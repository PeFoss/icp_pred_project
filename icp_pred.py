# -*- coding: utf-8 -*-
"""cleveland_clinic_lstm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fU_K5wtQGYnlaxApbG7lPc9naPeHdqGM

##Basic Imports
"""

import numpy as np
import pandas as pd
import math

"""##Mount Drive"""

# from google.colab import drive
# drive.mount('/content/drive')

"""##Read Data"""

df = pd.read_csv('Project1-Data/test1.csv')

df = df[::3]
df.reset_index(drop=True, inplace=True)
# df.head()

# df.info

# df.describe()

"""##Plot Correlations """

# import matplotlib.pyplot as plt
# import seaborn as sns

# sns.set_style('darkgrid')

# sns.scatterplot(data = df, x = 'MAP', y = 'ICP')

# sns.scatterplot(data = df[::100], x = 'MAP', y = 'ICP')

# sns.scatterplot(data = df, x = 'nICP', y = 'ICP')

# sns.scatterplot(data = df[::100], x = 'nICP', y = 'ICP')

# sns.scatterplot(data=df[::100], x='MAP', y='nICP')

"""###Histogram for ICP"""

# sns.histplot(data=df['ICP'], bins=30)

"""#Build and Evaluate model

##Imports
"""

from sklearn.preprocessing import MinMaxScaler

from sklearn.model_selection import train_test_split, KFold

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow import keras

from sklearn.metrics import mean_squared_error

"""##Preprocessing function"""

def process_data(column, sequence_length):
  x = df.drop(columns=['ICP'], axis=1)

  x = x[:round(x.values.shape[0]/sequence_length)*sequence_length]
  print(x.shape)
  x = x.values.reshape(int(x.values.shape[0]/sequence_length), sequence_length, 2)
  y = df['ICP']
  y = y[:round(y.values.shape[0]/sequence_length)*sequence_length]
  y = y.values.reshape(int(y.values.shape[0]/sequence_length), sequence_length)
  Xtrain, Xtest, ytrain, ytest = train_test_split(x, y, test_size=0.3, random_state=42)
  ytrain = ytrain.reshape(ytrain.shape[0], ytrain.shape[1], 1)
  Xtrain = Xtrain.reshape(Xtrain.shape[0], Xtrain.shape[1], 2)
  Xtest = Xtest.reshape(Xtest.shape[0], Xtest.shape[1], 2)
  return Xtrain, Xtest, ytrain, ytest

"""##Split Train and Test data"""

scaler = MinMaxScaler()
df = scaler.fit_transform(df)
df = pd.DataFrame(df, columns = [['MAP', 'ICP', 'nICP']])
Xtrain, Xtest, ytrain, ytest = process_data('MAP', 100)

"""##Build model"""

# kfold = KFold(n_splits=5, shuffle=True)
# kfold_performances = []
# for train, test in kfold.split(Xtrain):
#   model = Sequential()

#   lr = keras.optimizers.schedules.ExponentialDecay(
#       initial_learning_rate=0.001,
#       decay_steps=100000,
#       decay_rate=0.97)

#   model.add(LSTM(250, activation='relu', input_shape=(None, 1), return_sequences=True))
#   model.add(Dense(300))
#   model.add(Dense(300))
#   model.add(Dense(300))
#   model.add(Dense(1))
#   model.compile(optimizer=keras.optimizers.Adam(lr), loss='mse')
#   model.fit(Xtrain[train], ytrain[train], epochs=100, batch_size=126, verbose=1)
#   performace = model.evaluate(Xtrain[test], ytrain[test])
#   kfold_performances.append(performace)
# kfold_performances

# model = Sequential()

# lr = keras.optimizers.schedules.ExponentialDecay(
#       initial_learning_rate=0.001,
#       decay_steps=100000,
#       decay_rate=0.97)

# model.add(LSTM(250, activation='relu', input_shape=(100, 1), return_sequences=True))
# model.add(Dense(500))
# model.add(Dense(500))
# model.add(Dense(1))
# model.compile(optimizer=keras.optimizers.Adam(lr), loss='mse')
# model.fit(Xtrain, ytrain, epochs=100, batch_size=126, verbose=1)

"""##Notes
Extra hidden layer: Overfitting

More hidden nodes: Slower training and no significant improvements

####Learning Rate
* Less than 0.003: Slow training (does not reach minimum)
* More than 0.003: Learning rate too large and loss goes to infinity

##Train model
"""

# model.fit(Xtrain, ytrain, epochs=100, batch_size=128, verbose=1)

# model.summary()

# from keras.utils.vis_utils import plot_model
# plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)

"""##Evaluate Model"""

# predictX = model.predict(Xtest)

# model.evaluate(Xtest, ytest)

"""##Graph predicted Y vs. expected Y"""

# predictX, ytest, Xtest = predictX.flatten(), ytest.flatten(), Xtest.flatten()
# ytest = pd.DataFrame(ytest)
# predictX = pd.DataFrame(predictX)
# Xtest = pd.DataFrame(Xtest)
# df_predicts = pd.concat([ytest, predictX, Xtest], axis=1)
# df_predicts.columns = ['Y test', 'Y Predicts', 'X test']
# df_predicts.set_index('X test', inplace=True)
# sns.scatterplot(data=df_predicts, x='Y Predicts', y='Y test')



# sns.lineplot(data=df_predicts)

"""y predict vs. y train

sequence of 25 or 50 then plot 20 test-predict of 20 random samples
Plot ytest vs Xtest and yPredict vs. Xtest
"""

# sns.scatterplot(data=df_predicts.iloc[1200:1300, :], x='Y Predicts', y='Y test')

# sns.lineplot(data=df_predicts.iloc[:100, :])

# sns.lineplot(data=df_predicts.iloc[210:310, :])

# sns.lineplot(data=df_predicts.iloc[2310:2410, :])

# sns.lineplot(data=df_predicts.iloc[8653:8753, :])



"""#Seq2Seq Model"""

import tensorflow as tf
import random

"""####Hyperparameters"""

lr = tf.keras.optimizers.schedules.ExponentialDecay(
      initial_learning_rate=1e-3,
      decay_steps=100000,
      decay_rate=0.98)
batch_size = 512
epochs = 1

hidden_size = 1024
input_size_encoder = 2
input_size_decoder = 1
output_size = 1
num_layers = 1
dropout_rate = 0.5
tf.random.set_seed(1234)
np.random.seed(1234)

"""####Encoder"""

# class Encoder(tf.keras.layers.Layer):
#   def __init__(self, input_size,  hidden_size, num_layers, p):
#     super(Encoder, self).__init__()
#     self.dropout = tf.keras.layers.Dropout(p)
#     self.hidden_size = hidden_size
#     self.num_layers = num_layers

#     # self.rnn = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(hidden_size, input_size=(None, input_size), return_sequences=True, return_state=True))
#     self.rnn = tf.keras.layers.LSTM(hidden_size, input_shape=(None, input_size), return_sequences=True, return_state=True)
    

#   def call(self, x):

#     input_vec = self.dropout(x, training = True)
#     print("running encoder")
    
#     encoder_states, hidden, cell = self.rnn(input_vec)
#     print("ran encoder")


#     return encoder_states, hidden, cell
    
# """####Decoder"""

# class Decoder(tf.keras.layers.Layer):
#   def __init__(self, size_input, hidden_size, output_size, num_layers, p):
#     super(Decoder, self).__init__()
#     self.dropout = tf.keras.layers.Dropout(p)
#     self.hidden_size = hidden_size
#     self.num_layers = num_layers

#     self.rnn = tf.keras.layers.LSTM(hidden_size, input_shape=(None, hidden_size + size_input), dropout = p, return_sequences=True, return_state=True)
#     self.energy = tf.keras.layers.Dense(1, activation = None)
#     self.softmax = tf.nn.softmax
#     self.relu = tf.nn.relu

#     self.fc = tf.keras.layers.Dense(1, activation = None)

#   def call(self, x, encoder_states, hidden, cell):
#     print(hidden.shape)
#     print("New hidden ", hidden.shape)
#     input_vec = self.dropout(x, training = True)

#     sequence_length = encoder_states.shape[1]
#     h_reshaped = np.tile(tf.reshape(hidden, [hidden.shape[0], 1, hidden.shape[1]]), (1, sequence_length, 1))

#     concat_hidden_encoder = tf.concat([h_reshaped, encoder_states], axis=2)
#     print('concat shape', concat_hidden_encoder.shape)

#     energy = self.energy(concat_hidden_encoder)
#     energy = self.relu(energy)

#     attention = self.softmax(energy, axis = 0)

#     attention = tf.transpose(attention, perm = [0, 2, 1])

#     context_vector = tf.linalg.matmul(attention, encoder_states)
    
#     rnn_input = tf.concat([context_vector, input_vec], axis = 2)
#     print("Shape rnn_input", rnn_input.shape)
#     outputs = self.rnn(rnn_input, initial_state=[hidden, cell])
#     hidden = outputs[1]
#     cell = outputs[2]
#     outputs = outputs[0]
#     print("Ran decoder")

#     predictions = self.fc(outputs)

#     predictions = tf.squeeze(predictions, axis = 2)
#     print("Predictions shape:", predictions.shape)

#     return predictions, hidden, cell


# class Seq2Seq(tf.keras.Model):
#   def __init__(self, encoder, decoder):
#     super(Seq2Seq, self).__init__()
#     self.encoder = encoder
#     self.decoder = decoder
  
#   def call(self, inputs):
#     source = inputs[0]
#     print(source.shape)
#     # source = tf.reshape(source, [batch_size, source.shape[1], source.shape[2]])
#     target = inputs[1]
#     target_len = source.shape[1]

#     outputs = []

#     encoder_states, hidden, cell = self.encoder(source)

#     x = target[:, 0]
#     print("shape x: ", x.shape) 
#     x = tf.reshape(x, [x.shape[0], 1, x.shape[1]])

#     for t in range(1, target_len + 1):
#       print("time: ", t)

#       output, hidden, cell = self.decoder(x, encoder_states, hidden, cell)

#       outputs.append(output)
#       if t == target_len:
#         x = tf.expand_dims(output, axis=2)
#       else:
#         x =  tf.reshape(target[:, t], [target[:, t].shape[0], 1, target[:, t].shape[1]]) if random.random() < 0.5 else tf.expand_dims(output, axis=2)
      
#     return tf.transpose(tf.Variable(outputs), perm = [1, 0, 2])


# encoder = Encoder(input_size_encoder, hidden_size, num_layers, dropout_rate)
# decoder = Decoder(input_size_decoder, hidden_size, output_size, num_layers, dropout_rate)
# model = Seq2Seq(encoder, decoder)

# train_dataset = tf.data.Dataset.from_tensor_slices((Xtrain, ytrain))
# train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)

# optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)

# model.compile(optimizer, loss=tf.keras.losses.MeanSquaredError())

# model.fit([Xtrain, ytrain], ytrain, epochs=5, batch_size=64)

# loss_fn = tf.keras.losses.MeanSquaredError()

# epochs = 2
# for epoch in range(epochs):
#     print("\nStart of epoch %d" % (epoch,))

#     # Iterate over the batches of the dataset.
#     for step, inputs in enumerate(train_dataset):
#         with tf.GradientTape() as tape:
#             tape.watch(model.trainable_weights)
#             # Run the forward pass of the layer.
#             # The operations that the layer applies
#             # to its inputs are going to be recorded
#             # on the GradientTape.
#             # prediction = model(input, training=False)  # Logits for this minibatch
#             output = model(inputs)
#             print('prediction: {}'.format(output))
#             # Compute the loss value for this minibatch.
#             loss_value = loss_fn(inputs[1], output)
#         # Use the gradient tape to automatically retrieve
#         # the gradients of the trainable variables with respect to the loss.
#         grads = tape.gradient(loss_value, model.trainable_weights)
#         print(grads)  # output: [None]
#         # Run one step of gradient descent by updating
#         # the value of the variables to minimize the loss.

#         optimizer.apply_gradients(zip(grads, model.trainable_weights))

#         print('Iteration {}'.format(step))

# class CrossAttention(tf.keras.layers.Layer):
#   def __init__(self):
#     super().__init__()
#     self.mha = tf.keras.layers.MultiHeadAttention(key_dim=3, num_heads=1)
#     self.layernorm = tf.keras.layers.LayerNormalization()
#     self.add = tf.keras.layers.Add()

#   def call(self, x, context):

#     attn_output = self.mha(
#         query=x,
#         value=context,
#         )

  
#     x = self.add([x, attn_output])
#     x = self.layernorm(x)

#     return x

# class Encoder(tf.keras.layers.Layer):
#   def __init__(self, input_size,  hidden_size, num_layers, p):
#     super(Encoder, self).__init__()
#     self.dropout = tf.keras.layers.Dropout(p)
#     self.hidden_size = hidden_size
#     self.num_layers = num_layers

#     # self.rnn = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(hidden_size, input_size=(None, input_size), return_sequences=True, return_state=True))
#     self.rnn = tf.keras.layers.LSTM(hidden_size, input_shape=(None, input_size), return_sequences=True, return_state=True)
    

#   def call(self, x):

#     input_vec = self.dropout(x, training = True)
#     print("running encoder")
    
#     encoder_states, hidden, cell = self.rnn(input_vec)
#     print("ran encoder")


#     return encoder_states, hidden, cell
    
# """####Decoder"""

# class Decoder(tf.keras.layers.Layer):
#   def __init__(self, input_size, hidden_size, output_size, num_layers, p):
#     super(Decoder, self).__init__()
#     self.dropout = tf.keras.layers.Dropout(p)
#     self.hidden_size = hidden_size
#     self.num_layers = num_layers

#     self.rnn = tf.keras.layers.LSTM(hidden_size, input_shape=(None, input_size), dropout = p, return_sequences=True, return_state=True)
#     self.dense = tf.keras.layers.Dense(output_size, activation = None)
    
#   def call(self, x, hidden, cell):

#     input_vec = self.dropout(x, training = True)
    
#     print("Shape rnn_input", input_vec.shape)
#     outputs = self.rnn(input_vec, initial_state=[hidden, cell])
#     hidden = outputs[1]
#     cell = outputs[2]
#     outputs = outputs[0]
#     print("Ran decoder")

#     predictions = self.dense(outputs)

#     predictions = tf.squeeze(predictions, axis = 2)
#     print("Predictions shape:", predictions.shape)

#     return predictions, hidden, cell


# class Seq2Seq(tf.keras.Model):
#   def __init__(self, input_size_encoder, input_size_decoder, hidden_size, output_size, num_layers, dropout_rate):
#     super(Seq2Seq, self).__init__()
#     self.encoder = Encoder(input_size_encoder, hidden_size, num_layers, dropout_rate)
#     self.decoder = Decoder(input_size_decoder, hidden_size, output_size, num_layers, dropout_rate)

  
#   def call(self, inputs):
#     print('Inputs', inputs)
#     source = inputs[0]
#     print(source.shape)
#     # source = tf.reshape(source, [batch_size, source.shape[1], source.shape[2]])
#     print(source[0], source[60])
#     target = inputs[1]
#     target_len = source.shape[1]

#     outputs = []

#     _, hidden, cell = self.encoder(source)

#     x = target[:, 0]
#     print("shape x: ", x.shape) 
#     x = tf.reshape(x, [x.shape[0], 1, x.shape[1]])

#     for t in range(1, target_len + 1):
#       print("time: ", t)

#       output, hidden, cell = self.decoder(x, hidden, cell)

#       outputs.append(output)
#       if t == target_len:
#         x = tf.expand_dims(output, axis=2)
#       else:
#         x =  tf.reshape(target[:, t], [target[:, t].shape[0], 1, target[:, t].shape[1]]) if random.random() < 0.5 else tf.expand_dims(output, axis=2)
      
#     return tf.transpose(tf.Variable(outputs), perm = [1, 0, 2])

# model = Seq2Seq(input_size_encoder, input_size_decoder, hidden_size, output_size, num_layers, dropout_rate)

# model.compile(optimzer='adam', loss='mse')

# model.fit([Xtrain, ytrain], ytrain, epochs=5, batch_size=64)

# train_dataset = tf.data.Dataset.from_tensor_slices((Xtrain, ytrain))
# train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)

# optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)

# loss_fn = tf.keras.losses.MeanSquaredError()

# epochs = 2
# for epoch in range(epochs):
#     print("\nStart of epoch %d" % (epoch,))

#     # Iterate over the batches of the dataset.
#     for step, inputs in enumerate(train_dataset):
#         with tf.GradientTape() as tape:
#             # Run the forward pass of the layer.
#             # The operations that the layer applies
#             # to its inputs are going to be recorded
#             # on the GradientTape.
#             # prediction = model(input, training=False)  # Logits for this minibatch
#             output = model(inputs)
#             print('prediction: {}'.format(output))
#             # Compute the loss value for this minibatch.
#             loss_value = loss_fn(inputs[1], output)
#             # Use the gradient tape to automatically retrieve
#             # the gradients of the trainable variables with respect to the loss.
#             grads = tape.gradient(loss_value, model.trainable_weights)
#             print(grads)  # output: [None]
#             # Run one step of gradient descent by updating
#             # the value of the variables to minimize the loss.

#             optimizer.apply_gradients(zip(grads, model.trainable_weights))

#         print('Iteration {}'.format(step))

""""
Model built using Keras API, 
rather than tensorflow subclassing
"""""

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Dense

# encoder_inputs = Input(shape=(None, input_size_encoder))
# encoder = LSTM(hidden_size, return_state=True, return_sequences=True)
# encoder_outputs, state_h, state_c = encoder(encoder_inputs)

# # We discard `encoder_outputs` and only keep the states.
# encoder_states = [state_h, state_c]

# # Set up the decoder, using `encoder_states` as initial state.
# decoder_inputs = Input(shape=(None, input_size_decoder))
# # We set up our decoder to return full output sequences,
# # and to return internal states as well. We don't use the 
# # return states in the training model, but we will use them in inference.
# decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True)
# decoder_outputs, _, _ = decoder_lstm(decoder_inputs,
#                                      initial_state=encoder_states)
# decoder_dense = Dense(output_size, activation=None)
# decoder_outputs = decoder_dense(decoder_outputs)

# # Define the model that will turnimage/pjpeg;base64,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
# # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`
# model = Model([encoder_inputs, decoder_inputs], decoder_outputs)

# model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss='mse')

# ytarget = ytrain[:, :-1, :]
# ytarget = np.concatenate((np.zeros([ytrain.shape[0], 1, ytrain.shape[2]]), ytarget), axis=1)


# model.fit([Xtrain, ytarget], ytrain,
#           batch_size=batch_size,
#           epochs=epochs)


kfold = KFold(n_splits=5, shuffle=True)
kfold_performances = []
for train, test in kfold.split(Xtrain):

  Xtest_validate = Xtrain[test]
  ytest_validate = ytrain[test]


  Xtrain_validate = Xtrain[train]
  ytrain_validate = ytrain[train]


  y_target_train = ytrain_validate[:, :-1, :]
  y_target_train = np.concatenate((np.zeros([ytrain_validate.shape[0], 1, ytrain_validate.shape[2]]), y_target_train), axis=1)

  y_target_test = ytest_validate[:, :-1, :]
  y_target_test = np.concatenate((np.zeros([ytest_validate.shape[0], 1, ytest_validate.shape[2]]), y_target_test), axis=1)

  encoder_inputs = Input(shape=(None, input_size_encoder))
  encoder = LSTM(hidden_size, return_state=True, return_sequences=True)
  encoder_outputs, state_h, state_c = encoder(encoder_inputs)
  # We discard `encoder_outputs` and only keep the states.
  encoder_states = [state_h, state_c]

  # Set up the decoder, using `encoder_states` as initial state.
  decoder_inputs = Input(shape=(None, input_size_decoder))
  # We set up our decoder to return full output sequences,
  # and to return internal states as well. We don't use the 
  # return states in the training model, but we will use them in inference.
  decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True)
  decoder_outputs, _, _ = decoder_lstm(decoder_inputs,
                                      initial_state=encoder_states)
  decoder_dense = Dense(output_size, activation=None)
  decoder_outputs = decoder_dense(decoder_outputs)

  # Define the model that will turn
  # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`
  model = Model([encoder_inputs, decoder_inputs], decoder_outputs)


  model.compile(optimizer=keras.optimizers.Adam(lr), loss='mse')
  model.fit([Xtrain_validate, y_target_train], ytrain_validate,
          batch_size=batch_size,
          epochs=epochs,
          verbose = 1)
  performace = model.evaluate([Xtest_validate, y_target_test], ytest_validate)
  kfold_performances.append(performace)
print('Result of Kfold validation', kfold_performances)

#Inference 

encoder_model = Model(encoder_inputs, encoder_states)
decoder_state_input_h = Input(shape=(hidden_size,))
decoder_state_input_c = Input(shape=(hidden_size,))
decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]
decoder_outputs, state_h, state_c = decoder_lstm(
    decoder_inputs, initial_state=decoder_states_inputs)
decoder_states = [state_h, state_c]
decoder_outputs = decoder_dense(decoder_outputs)
decoder_model = Model(
    [decoder_inputs] + decoder_states_inputs,
    [decoder_outputs] + decoder_states)

def seq2seq(input_test):
  state = encoder_model.predict(input_test)

  target_seq = np.zeros((input_test.shape[0], 1, 1))

  target_len = input_test.shape[1]
  print(target_len)

  stop_condition = False 

  outputs = []

  seq_index = 0

  while not stop_condition:
    output_tokens, h, c = decoder_model.predict(
            [target_seq] + state)

    state = [h, c]

    outputs.append(output_tokens)

    target_seq = output_tokens

    seq_index += 1

    if seq_index == target_len:
      stop_condition = True

    if stop_condition:
      break

  return np.concatenate(outputs, axis=1)



outputs = seq2seq(Xtest)

print("outputs", outputs)

print("shape outputs", outputs.shape)

outputs, ytest, Xtest = outputs.flatten(), ytest.flatten(), Xtest[:, :, 1].flatten()
ytest = pd.DataFrame(ytest)
predictX = pd.DataFrame(outputs)
Xtest = pd.DataFrame(Xtest)
df_predicts = pd.concat([ytest, predictX, Xtest], axis=1)
df_predicts.columns = ['Y test', 'Y Predicts', 'X test']
df_predicts.set_index('X test', inplace=True)

#Model based on slides

# class Encoder(tf.keras.layers.Layer):
#   def __init__(self, num_features, hidden_size, dropout):
#     self.dropout = tf.keras.layers.Dropout(dropout)
#     self.rnn = tf.keras.layers.LSTM(hidden_size, input_size=(None, num_features), return_sequences=True, return_state=True)

#   def call(self, x):
#     x = self.dropout(x)

#     encoder_outputs, hidden_state, cell_state = self.rnn(x)

#     return encoder_outputs, hidden_state, cell_state


# class Attention(tf.keras.layers.Layer):
#   def __init__(self):
#     super().__init__()
#     self.mha = tf.keras.layers.MultiHeadAttention(key_dim=3, num_heads=1)
#     self.layernorm = tf.keras.layers.LayerNormalization()
#     self.add = tf.keras.layers.Add()

#   def call(self, x, context):

#     attn_output = self.mha(
#         query=x,
#         value=context,
#         )

  
#     x = self.add([x, attn_output])
#     x = self.layernorm(x)

#     return x

# class Decoder(tf.keras.layers.Layer):
#   def __init__(self, num_features, hidden_size, dropout):
#     self.droupout = tf.keras.layers.Dropout(dropout)
#     self.rnn = tf.keras.layers.LSTM(hidden_size, input_size=(None, num_features), return_sequences=True, return_state=True)
#     self.dense = tf.keras.layers.Dense(output_size, activation='linear')
#     self.attention = Attention()
  
#   def call(self, x, encoder_output, hidden, cell):
#     x = self.dropout(x)

#     rnn_output = self.rnn(x, initial_state=[hidden, cell])

#     dense_input = self.attention(rnn_output, encoder_output)

#     output = self.dense(dense_input)

#     return output


# class Seq2Seq(tf.keras.Model):
#   def __init__(self, num_features, hidden_size, dropout):
#     self.encoder = Encoder(num_features, hidden_size, dropout)
#     self.decoder = Decoder(num_features, hidden_size, dropout)

#   def call(self, inputs):
#     original, target = inputs

#     enc_outputs, hidden, cell = self.encoder(original)

#     output = self.decoder(target, enc_outputs, hidden, cell)

#     return output



"""
Correct model with teacher force ratio:
train with only one time step as output, 
then previous loop for prediction
"""